input {

  file {
    type => "linux-syslog"
    path => "/var/log/message"
}

 file {
    path => [ "/home/*/access-logs/*" ]
    type => "apache-access"
  }

  file {
    type => "apache-error"
    path => "/usr/local/apache/logs/error.log"
  }

  file {
    type => "kern-log"
    path => "/var/log/frewall.log"
  }

  file {
    path => [ "/var/log/exim_mainlog", "/var/log/exim_rejectlog"]
    type => "exim-log"
    start_position => 'beginning'
    sincedb_path => "/dev/null"
    }
}


filter {

 if [type] == "exim-log" {

   # Strip out lines we don't need using the regexp in the patterns file
  if [message] =~ /%{EXIM_EXCLUDE_TERMS}/ {
    drop { }
  }

  # Really, really dirty hack to workaround bug in grok code
  # which won't handle multiple matches on the same field
  mutate {
    add_field => {
      "message_1" => "%{message}"
      "message_2" => "%{message}"
      "message_3" => "%{message}"
      "message_4" => "%{message}"
      "message_5" => "%{message}"
    }
  }

  grok {
    patterns_dir => "/opt/logstash/patterns/grok-patterns"
    break_on_match => false
    keep_empty_captures => true
    match => [
      "message_1", "(%{SYSLOGBASE} )(%{EXIM_DATE:exim_date} )?(%{EXIM_PID:exim_pid} )?(%{EXIM_MSGID:exim_msg_id} )(%{EXIM_FLAGS:exim_flags} )(%{GREEDYDATA})"
    ]
    match => [
      "message_2", "(%{EXIM_MSGID} )(<= )(%{NOTSPACE:env_sender} )(%{EXIM_REMOTE_HOST} )?(%{EXIM_INTERFACE} )?(%{EXIM_PROTOCOL} )?(X=%{NOTSPACE:tls_info} )?(A=%{NOTSPACE:exim_authenticator}:%{NOTSPACE:exim_username} )?(%{EXIM_MSG_SIZE} )?(%{EXIM_HEADER_ID} )?(%{EXIM_SUBJECT})"
    ]
    match => [
      "message_3", "(%{EXIM_MSGID} )([=-]> )(%{NOTSPACE:env_rcpt} )(<%{NOTSPACE:env_rcpt_outer}> )?(F=<%{NOTSPACE:env_sender}> )?(R=%{NOTSPACE:exim_router} )(T=%{NOTSPACE:exim_transport} )(%{EXIM_REMOTE_HOST} )(X=%{NOTSPACE:tls_info} )?(QT=%{EXIM_QT:exim_qt})?"
    ]
    match => [
      "message_4", "(%{SYSLOGBASE} )(%{EXIM_DATE:exim_date} )?(%{EXIM_PID:exim_pid} )?(%{EXIM_MSGID:exim_msg_id} )(Completed)( QT=%{EXIM_QT:exim_qt})?"
    ]
    match => [
      "message_5", "(%{SYSLOGBASE} )(%{EXIM_DATE:exim_date} )?(%{EXIM_PID:exim_pid} )?(%{EXIM_MSGID:exim_msg_id} )?(%{EXIM_REMOTE_HOST} )?(%EXIM_INTERFACE} )?(F=<%{NOTSPACE:env_sender}> )?(.+(rejected after DATA|rejected \(but fed to sa-learn\)|rejected [A-Z]+ (or [A-Z]+ %{NOTSPACE}?|<%{NOTSPACE:env_rcpt}>)?): (?<exim_rej_reason>.+))"
    ]
  }

  date {
    match => [ "timestamp", "MMM dd HH:mm:ss", "MMM  d HH:mm:ss", "ISO8601" ]
  }

  if "_grokparsefailure" in [tags] {
    drop { }
  }

  mutate {
    add_field => { "exim_msg_state" => "not_defined" }
  }

  if [exim_flags] == "<=" {
    mutate {
      update => [ "exim_msg_state", "received" ]
    }
  } else if [exim_flags] == "=>" {
    mutate {
       update => [ "exim_msg_state", "delivered" ]
    }
  } else if [exim_flags] == "->" {
    mutate {
       update => [ "exim_msg_state", "delivered" ]
    }
  } else if [exim_flags] == ">>" {
    mutate {
       update => [ "exim_msg_state", "cutthrough_delivery" ]
    }
  } else if [exim_flags] == "*>" {
    mutate {
       update => [ "exim_msg_state", "suppressed_delivery" ]
    }
  } else if [exim_flags] == "==" {
    mutate {
       update => [ "exim_msg_state", "deferred" ]
    }
  } else if [exim_flags] == "**" {
    mutate {
       update => [ "exim_msg_state", "failed" ]
    }
  } else if "Completed QT=" in [message] {
    mutate {
       update => [ "exim_msg_state", "completed" ]
    }
  } else if [message] =~ /(rejected after DATA|rejected \(but fed to sa-learn\))/ {
    mutate {
       update => [ "exim_msg_state", "rejected_after_data" ]
    }
  } else if " rejected " in [message] {
    mutate {
       update => [ "exim_msg_state", "rejected_smtp_transaction" ]
    }
  }

  # Ignore feeding sa-learn
  #
  if [message] =~ /R=feed_sa_learn T=feed_sa_learn/ {
    drop { }
  }

  # Look back through ES table for existence of previous entry
  # for this exim_msg_id being rejected & fed to Spam Assassin.
  # If entry is found, drop this log line (it's irrelevant).
  #
  if [exim_msg_state] == "completed" and [host_type] == "MX" {
    elasticsearch {
      query => 'exim_msg_id:"%{exim_msg_id}" AND exim_msg_state:"rejected_after_data"'
      fields => [ "exim_msg_state", "exim_msg_state2" ]
      #sort => "@timestamp:desc, ignore_unmapped:true"
      sort => "ignore_unmapped:true"
    }
    if [exim_msg_state2] == "rejected_after_data" {
      drop { }
    }
    mutate {
      remove_field => [ "query_failed" ]
    }
  }

  # Look back through ES table for the incoming message and
  # extract the envelope sender. Permits later stats creation
  # listing deliveries per env_sender
  if [exim_msg_state] == "delivered" {
    elasticsearch {
      query => 'exim_msg_id:"%{exim_msg_id}" AND exim_msg_state:"received"'
      #fields => [ "env_sender", "env_sender" ]
      fields => [ "env_sender", "env_sender", "remote_host", "remote_host", "remote_hostname", "remote_hostname" ]
      sort => "ignore_unmapped:true"
    }
    mutate {
      remove_field => [ "query_failed" ]
    }
  }

  # Not interested in non-actioned retries
  #
  if [exim_flags] == "==" and "retry time not reached" in [message] {
    drop { }
  }

  # Remove the really, really dirty hack to workaround bug in grok code
  # which won't handle multiple matches on the same field
  mutate {
    remove_field => [ "message_1","message_2","message_3","message_4","message_5" ]
  }


 }


 if [type] == "kern-log" {
        grok {
                match => { "message" => "%{IPTABLES}"}
                patterns_dir => ["/opt/logstash/patterns/grok-patterns"]
        }
 }

if [src_ip]  {
    geoip {
      source => "src_ip"
      target => "geoip"
      add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
      add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
    }
    mutate {
      convert => [ "[geoip][coordinates]", "float" ]
    }
  }

  if [type] == "linux-syslog" {
      grok {
        match => { "message" => "Accepted %{WORD:auth_method} for %{USER:username} from %{IP:src_ip} port %{INT:src_port} ssh2" }
      }
      grok {
        match => { "message" => "Invalid user %{USER:username} from %{IP:src_ip}" }
      }
  }

  if [type] == "apache-access" {
      grok {
        match => { "message" => "%{COMBINEDAPACHELOG}" }
      }
  }

  if [type] == "apache-error" {
      grok {
        match => { "message" => "%{APACHEERRORLOG}" }
        patterns_dir => ["/opt/logstash/patterns/grok-patterns"]
      }

  }
   if [clientip]  {
    geoip {
      source => "clientip"
      target => "geoip"
      add_field => [ "[geoip][coordinates]", "%{[geoip][longitude]}" ]
      add_field => [ "[geoip][coordinates]", "%{[geoip][latitude]}"  ]
    }
    mutate {
      convert => [ "[geoip][coordinates]", "float" ]
    }
  }
}

output {
  elasticsearch {
    host => "xx.xx.xx.xx"
  }
  stdout { codec => rubydebug }
}